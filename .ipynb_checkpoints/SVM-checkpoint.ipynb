{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM\n",
    "Suport Vector Machine work separing the data with hyperplanes (lines), we said hyperplanes because you can separate the N-dimensional data, with a simple line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC, SVR\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, f1_score, confusion_matrix, accuracy_score, mean_absolute_error, mean_squared_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "\n",
    "Explanation of the features:\n",
    "1. Avg. Session Length: mean of the session per user, in minutes\n",
    "2. Time on App: the mean of all sessions in app, in minutes\n",
    "3. Time on Website: the mean of all sessions in website, in minutes\n",
    "4. Length of Membership: the length of membership, in years\n",
    "5. Yearly Amount Spent: the money spend last year, in euros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_customer = pd.read_csv('C:/Users/alberto.rubiales/PycharmProjects/Pycharm/SVM/Ecommerce Customers.csv')\n",
    "df_customer.drop(columns=['Email', 'Address', 'Avatar'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Avg. Session Length</th>\n",
       "      <th>Time on App</th>\n",
       "      <th>Time on Website</th>\n",
       "      <th>Length of Membership</th>\n",
       "      <th>Yearly Amount Spent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>34.497268</td>\n",
       "      <td>12.655651</td>\n",
       "      <td>39.577668</td>\n",
       "      <td>4.082621</td>\n",
       "      <td>587.951054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>31.926272</td>\n",
       "      <td>11.109461</td>\n",
       "      <td>37.268959</td>\n",
       "      <td>2.664034</td>\n",
       "      <td>392.204933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>33.000915</td>\n",
       "      <td>11.330278</td>\n",
       "      <td>37.110597</td>\n",
       "      <td>4.104543</td>\n",
       "      <td>487.547505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>34.305557</td>\n",
       "      <td>13.717514</td>\n",
       "      <td>36.721283</td>\n",
       "      <td>3.120179</td>\n",
       "      <td>581.852344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>33.330673</td>\n",
       "      <td>12.795189</td>\n",
       "      <td>37.536653</td>\n",
       "      <td>4.446308</td>\n",
       "      <td>599.406092</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Avg. Session Length  Time on App  Time on Website  Length of Membership  \\\n",
       "0            34.497268    12.655651        39.577668              4.082621   \n",
       "1            31.926272    11.109461        37.268959              2.664034   \n",
       "2            33.000915    11.330278        37.110597              4.104543   \n",
       "3            34.305557    13.717514        36.721283              3.120179   \n",
       "4            33.330673    12.795189        37.536653              4.446308   \n",
       "\n",
       "   Yearly Amount Spent  \n",
       "0           587.951054  \n",
       "1           392.204933  \n",
       "2           487.547505  \n",
       "3           581.852344  \n",
       "4           599.406092  "
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_customer[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = df_customer.drop(columns=['Yearly Amount Spent'])\n",
    "test = df_customer['Yearly Amount Spent']\n",
    "X_train, X_test, y_train, y_test = train_test_split(train, test, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min: 256.67058229005585\n",
      "Max: 765.5184619388373\n"
     ]
    }
   ],
   "source": [
    "print('Min:', df_customer['Yearly Amount Spent'].min())\n",
    "print('Max:', df_customer['Yearly Amount Spent'].max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVR\n",
    "The SVM create a line to separate differents points, and create a \"margin\" to create the maximun distance betweent the line and the first point of this class. We can see in this image better \n",
    "<img src=\"https://miro.medium.com/max/2554/1*M_3iYollNTlz0PVn5udCBQ.png\" alt=\"svm\" width=500, height=500/>\n",
    "The light green is the line that separate the points and the darks green are called support vector, because are the lines that try to create the maximun expace between the line and the first point\n",
    "\n",
    "All datas are not linearly separable, so the algorithm elevate the data to N dimension, where N is the dimension that our data is linearly separable (N could be 2, 3, 5, 20, etc.). This is why is  not called line as we said before, it's called Hyperplane because is not technically a line. Now let see the hyperparamenters of this algorithm\n",
    "\n",
    "### Hyperparameters\n",
    "* kernel: the function that transfor our data, to the algorithm (known as \"Kernel Trick\")\n",
    "    * linear:help us to make good predictions when our data it's easy separable by lines\n",
    "    * poly: this kernel make a polynomial transformation of our features, creating new features that can be linearli separable\n",
    "    * rbf: Radial Basis Function, help us to make good predictions when our data it's easy separable by circles\n",
    "    * sigmoid:is similar to the logistic regression\n",
    "* degree: The degree that we want to use in polynomial kernel function (only for \"poly\" kernel)\n",
    "* gamma: only for non linear kernel (rbf, poy and sigmoid), is the how we adjust the region to our data points, could be: \n",
    "    * a number: if it's 0, the lines that separe our data will be straights, more high number, more curves are, a very high number, for example, 1000 will make that the line that separe our point are around each data, and our model will overfit\n",
    "    * scale: will use 1 / (n_features * X.var()) as a gamma\n",
    "    * auto: the default version\n",
    "* tol: tolerance for early stopping\n",
    "* C: in simple terms is how the model will accept bad classified points in order to reduce the complexity of the model controlling the support vector (the margin). more high is C, smaller is the support vectors and more complex is the model and viceversa\n",
    "* shrinking: True/False is a heuristic method to find a optimal solution faster, at least you have a very small dataset, it's strongly recommended to leave in True, because it hardly decreases the accuracy\n",
    "* cache_size: True/False is the use of the cache memory by the server, the more memory we use, the faster the algorithm. (1G as much is enough)\n",
    "* max_iter: the limit numbers of iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE in train: 41.215012264348445\n",
      "MSE in train: 57.88180711485425\n",
      "MAE in test: 50.40217277968557\n",
      "RMSE in test: 70.61553685377649\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alberto.rubiales\\miniconda3\\envs\\Pycharm\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "svr_1 = SVR()\n",
    "\n",
    "svr_1.fit(X_train, y_train)\n",
    "train_preds = svr_1.predict(X_train)\n",
    "test_preds = svr_1.predict(X_test)\n",
    "print('MAE in train:', mean_absolute_error(train_preds, y_train))\n",
    "print('MSE in train:', np.sqrt(mean_squared_error(train_preds, y_train)))\n",
    "print('MAE in test:', mean_absolute_error(test_preds, y_test))\n",
    "print('RMSE in test:', np.sqrt(mean_squared_error(test_preds, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE in train: 7.867107501756691\n",
      "MSE in train: 9.970500837610402\n",
      "MAE in test: 8.126463510052199\n",
      "RMSE in test: 10.196342962750743\n"
     ]
    }
   ],
   "source": [
    "svr_2 = SVR(kernel='linear', C=10, cache_size=800, )\n",
    "\n",
    "svr_2.fit(X_train, y_train)\n",
    "train_preds = svr_2.predict(X_train)\n",
    "test_preds = svr_2.predict(X_test)\n",
    "print('MAE in train:', mean_absolute_error(train_preds, y_train))\n",
    "print('MSE in train:', np.sqrt(mean_squared_error(train_preds, y_train)))\n",
    "print('MAE in test:', mean_absolute_error(test_preds, y_test))\n",
    "print('RMSE in test:', np.sqrt(mean_squared_error(test_preds, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Avg. Session Length</th>\n",
       "      <td>26.155967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Time on App</th>\n",
       "      <td>38.105086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Time on Website</th>\n",
       "      <td>1.581501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Length of Membership</th>\n",
       "      <td>61.874065</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              0\n",
       "Avg. Session Length   26.155967\n",
       "Time on App           38.105086\n",
       "Time on Website        1.581501\n",
       "Length of Membership  61.874065"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(svr_2.coef_, columns=X_train.columns).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So here we can see clearly **wich are the variables that more contribute to increase our incomes.**\n",
    "* Length of Membership: for each year more of membership, our customers spend 61 eur more\n",
    "* Time on App: for every minute our customers spend on the application, they spend 38 euros more.\n",
    "* Avg. Session Length: for every minute our customers spend on the application, they spend 25 euros more.\n",
    "* Time on Website: for every minute our customers spend on the website, they spend 39 cents more\n",
    "\n",
    "So we can extract different **conclusions** of this model:\n",
    "1. We have to make our customers use the application and stop using the web, because they buy more in the app\n",
    "2. We have to improve our web, because is important for our customer when they want to buy\n",
    "3. we have to try to make member users stay as long as possible, because the longest-lived users are the ones who spend the most. (For example if they want to cancel their membership, offer one month free, etc.)\n",
    "4. Our app works very well, so if we do even a better app and we get our users to use it longer, we'll increase sales.\n",
    "\n",
    "Etc, we always need to see the model and know the sector that we are working in order to make the bests decisions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVC\n",
    "Now we are use SMV in a classification problem, to do that, we need to create categories instead of continuous data. But first let see the new hyperparam that we have in SVC\n",
    "\n",
    "### Hyperparm\n",
    "* probability:\n",
    "* class_weight: to balance unbalanced datasets, could be:\n",
    "    * balanced: automatically the algorith balance de dataset\n",
    "    * we can pass a dictionary to our algorithm with the num of the class and their weight\n",
    "* decision_function_shap: the decision function that we will use to make the classification or multi-classification problem. could be:\n",
    "    * ovr: consists of taking one class as 0 and the rest of classes as 1 and train an algorithm, and make the same again with the rest of classes\n",
    "    * ovo: consist of taking two classes as 0 and 1 and train an algorithm. and make the same again with the rest of the classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "SVC?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([  7.,  14.,  42.,  86., 137., 116.,  63.,  23.,   9.,   3.]),\n",
       " array([256.67058229, 307.55537025, 358.44015822, 409.32494618,\n",
       "        460.20973415, 511.09452211, 561.97931008, 612.86409804,\n",
       "        663.74888601, 714.63367397, 765.51846194]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(df_customer['Yearly Amount Spent'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def money_spent_categorizer(money):\n",
    "    if money < 460:\n",
    "        return 0 #soft buyer\n",
    "    elif money >=460 and money <=540:\n",
    "        return 1 #medium buyer\n",
    "    else:\n",
    "        return 2 #heavy buyer\n",
    "    \n",
    "df_customer['buyer_type'] = df_customer.apply(lambda x: money_spent_categorizer(x['Yearly Amount Spent']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = df_customer.drop(columns=['Yearly Amount Spent', 'buyer_type'])\n",
    "test = df_customer['buyer_type']\n",
    "X_train, X_test, y_train, y_test = train_test_split(train, test, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLASSIFICATION IN TRAIN\n",
      "\n",
      "CONFUSION MATRIX:\n",
      " [[117   5   0]\n",
      " [  4 150   5]\n",
      " [  0   8 111]]\n",
      "\n",
      "F1 SCORE:\n",
      " 0.945\n",
      "\n",
      "CLASSIFICATION REPORT\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.96      0.96       122\n",
      "           1       0.92      0.94      0.93       159\n",
      "           2       0.96      0.93      0.94       119\n",
      "\n",
      "    accuracy                           0.94       400\n",
      "   macro avg       0.95      0.95      0.95       400\n",
      "weighted avg       0.95      0.94      0.95       400\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alberto.rubiales\\miniconda3\\envs\\Pycharm\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "#instance\n",
    "svc_1 = SVC()\n",
    "\n",
    "#train\n",
    "svc_1.fit(X_train, y_train)\n",
    "\n",
    "#train preds\n",
    "preds_train = svc_1.predict(X_train)\n",
    "\n",
    "#metrics classifications in train\n",
    "print('CLASSIFICATION IN TRAIN')\n",
    "print()\n",
    "print('CONFUSION MATRIX:\\n', confusion_matrix(preds_train, y_train))\n",
    "print()\n",
    "print('F1 SCORE:\\n', f1_score(preds_train, y_train, average='micro'))\n",
    "print()\n",
    "print('CLASSIFICATION REPORT\\n',classification_report(preds_train, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLASSIFICATION IN TEST\n",
      "\n",
      "CONFUSION MATRIX:\n",
      " [[27  1  0]\n",
      " [ 0 38  3]\n",
      " [ 0  2 29]]\n",
      "\n",
      "F1 SCORE:\n",
      " 0.94\n",
      "\n",
      "CLASSIFICATION REPORT\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.96      0.98        28\n",
      "           1       0.93      0.93      0.93        41\n",
      "           2       0.91      0.94      0.92        31\n",
      "\n",
      "    accuracy                           0.94       100\n",
      "   macro avg       0.94      0.94      0.94       100\n",
      "weighted avg       0.94      0.94      0.94       100\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Classification in test\n",
    "preds_trest = svc_1.predict(X_test)\n",
    "\n",
    "#metrics classifications in train\n",
    "print('CLASSIFICATION IN TEST')\n",
    "print()\n",
    "print('CONFUSION MATRIX:\\n', confusion_matrix(preds_trest, y_test))\n",
    "print()\n",
    "print('F1 SCORE:\\n', f1_score(preds_trest, y_test, average='micro'))\n",
    "print()\n",
    "print('CLASSIFICATION REPORT\\n',classification_report(preds_trest, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLASSIFICATION IN TRAIN\n",
      "\n",
      "CONFUSION MATRIX:\n",
      " [[117   6   0]\n",
      " [  4 148   2]\n",
      " [  0   9 114]]\n",
      "\n",
      "F1 SCORE:\n",
      " 0.9475\n",
      "\n",
      "CLASSIFICATION REPORT\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.95      0.96       123\n",
      "           1       0.91      0.96      0.93       154\n",
      "           2       0.98      0.93      0.95       123\n",
      "\n",
      "    accuracy                           0.95       400\n",
      "   macro avg       0.95      0.95      0.95       400\n",
      "weighted avg       0.95      0.95      0.95       400\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#instance\n",
    "svc_2 = SVC(kernel='rbf', class_weight='balanced', decision_function_shape='ovo', C=1.2, gamma=0.1, probability=True)\n",
    "\n",
    "#train\n",
    "svc_2.fit(X_train, y_train)\n",
    "\n",
    "#train preds\n",
    "preds_train = svc_2.predict(X_train)\n",
    "\n",
    "#metrics classifications in train\n",
    "print('CLASSIFICATION IN TRAIN')\n",
    "print()\n",
    "print('CONFUSION MATRIX:\\n', confusion_matrix(preds_train, y_train))\n",
    "print()\n",
    "print('F1 SCORE:\\n', f1_score(preds_train, y_train, average='micro'))\n",
    "print()\n",
    "print('CLASSIFICATION REPORT\\n',classification_report(preds_train, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLASSIFICATION IN TEST\n",
      "\n",
      "CONFUSION MATRIX:\n",
      " [[27  1  0]\n",
      " [ 0 38  1]\n",
      " [ 0  2 31]]\n",
      "\n",
      "F1 SCORE:\n",
      " 0.96\n",
      "\n",
      "CLASSIFICATION REPORT\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.96      0.98        28\n",
      "           1       0.93      0.97      0.95        39\n",
      "           2       0.97      0.94      0.95        33\n",
      "\n",
      "    accuracy                           0.96       100\n",
      "   macro avg       0.97      0.96      0.96       100\n",
      "weighted avg       0.96      0.96      0.96       100\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Classification in test\n",
    "preds_trest = svc_2.predict(X_test)\n",
    "\n",
    "#metrics classifications in train\n",
    "print('CLASSIFICATION IN TEST')\n",
    "print()\n",
    "print('CONFUSION MATRIX:\\n', confusion_matrix(preds_trest, y_test))\n",
    "print()\n",
    "print('F1 SCORE:\\n', f1_score(preds_trest, y_test, average='micro'))\n",
    "print()\n",
    "print('CLASSIFICATION REPORT\\n',classification_report(preds_trest, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have improve our **accuracy in 2%.** Nice!  \n",
    "\n",
    "Our model is not linear, because we use the RBF kernel, so we don't have coefficients. So if we want to know how each feature affect to the decission we need to make and the amount of information that give to us, we need to make some extra calculations that we will learn in another notebook :).  \n",
    "\n",
    "Finally we will se the probabilitys of each user for each class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Avg. Session Length</th>\n",
       "      <th>Time on App</th>\n",
       "      <th>Time on Website</th>\n",
       "      <th>Length of Membership</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>36.139662</td>\n",
       "      <td>12.050267</td>\n",
       "      <td>36.959643</td>\n",
       "      <td>3.864861</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>33.025020</td>\n",
       "      <td>12.504220</td>\n",
       "      <td>37.645839</td>\n",
       "      <td>4.051382</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>32.070546</td>\n",
       "      <td>11.733106</td>\n",
       "      <td>37.534291</td>\n",
       "      <td>4.671275</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>32.189845</td>\n",
       "      <td>11.386776</td>\n",
       "      <td>38.197483</td>\n",
       "      <td>4.808320</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>31.885406</td>\n",
       "      <td>11.281931</td>\n",
       "      <td>37.385318</td>\n",
       "      <td>2.877225</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>34.394327</td>\n",
       "      <td>12.807752</td>\n",
       "      <td>38.551030</td>\n",
       "      <td>1.810080</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>32.903454</td>\n",
       "      <td>10.542645</td>\n",
       "      <td>35.533864</td>\n",
       "      <td>3.091827</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>33.236266</td>\n",
       "      <td>10.972554</td>\n",
       "      <td>34.574028</td>\n",
       "      <td>2.931620</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>33.924625</td>\n",
       "      <td>11.911416</td>\n",
       "      <td>38.274702</td>\n",
       "      <td>2.910038</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>33.200616</td>\n",
       "      <td>11.965980</td>\n",
       "      <td>36.831536</td>\n",
       "      <td>3.549036</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>32.646777</td>\n",
       "      <td>11.499409</td>\n",
       "      <td>38.332576</td>\n",
       "      <td>4.958264</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>33.154176</td>\n",
       "      <td>11.887494</td>\n",
       "      <td>36.265001</td>\n",
       "      <td>2.602287</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>34.878495</td>\n",
       "      <td>13.067896</td>\n",
       "      <td>36.678222</td>\n",
       "      <td>1.920715</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>31.765619</td>\n",
       "      <td>12.442617</td>\n",
       "      <td>38.131712</td>\n",
       "      <td>3.850280</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>31.851253</td>\n",
       "      <td>12.418962</td>\n",
       "      <td>35.977652</td>\n",
       "      <td>3.251742</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>33.428747</td>\n",
       "      <td>10.636761</td>\n",
       "      <td>37.578835</td>\n",
       "      <td>2.926396</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>32.149061</td>\n",
       "      <td>10.047315</td>\n",
       "      <td>37.181447</td>\n",
       "      <td>3.535088</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>32.342796</td>\n",
       "      <td>11.409645</td>\n",
       "      <td>35.777782</td>\n",
       "      <td>3.872432</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>32.116400</td>\n",
       "      <td>12.380695</td>\n",
       "      <td>37.232003</td>\n",
       "      <td>3.089528</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>33.481931</td>\n",
       "      <td>11.918670</td>\n",
       "      <td>37.317705</td>\n",
       "      <td>3.336339</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Avg. Session Length  Time on App  Time on Website  Length of Membership  \\\n",
       "0             36.139662    12.050267        36.959643              3.864861   \n",
       "1             33.025020    12.504220        37.645839              4.051382   \n",
       "2             32.070546    11.733106        37.534291              4.671275   \n",
       "3             32.189845    11.386776        38.197483              4.808320   \n",
       "4             31.885406    11.281931        37.385318              2.877225   \n",
       "5             34.394327    12.807752        38.551030              1.810080   \n",
       "6             32.903454    10.542645        35.533864              3.091827   \n",
       "7             33.236266    10.972554        34.574028              2.931620   \n",
       "8             33.924625    11.911416        38.274702              2.910038   \n",
       "9             33.200616    11.965980        36.831536              3.549036   \n",
       "10            32.646777    11.499409        38.332576              4.958264   \n",
       "11            33.154176    11.887494        36.265001              2.602287   \n",
       "12            34.878495    13.067896        36.678222              1.920715   \n",
       "13            31.765619    12.442617        38.131712              3.850280   \n",
       "14            31.851253    12.418962        35.977652              3.251742   \n",
       "15            33.428747    10.636761        37.578835              2.926396   \n",
       "16            32.149061    10.047315        37.181447              3.535088   \n",
       "17            32.342796    11.409645        35.777782              3.872432   \n",
       "18            32.116400    12.380695        37.232003              3.089528   \n",
       "19            33.481931    11.918670        37.317705              3.336339   \n",
       "\n",
       "       0     1     2  \n",
       "0   0.01  0.02  0.98  \n",
       "1   0.00  0.10  0.89  \n",
       "2   0.01  0.71  0.28  \n",
       "3   0.01  0.89  0.10  \n",
       "4   1.00  0.00  0.00  \n",
       "5   0.76  0.20  0.04  \n",
       "6   1.00  0.00  0.00  \n",
       "7   1.00  0.00  0.00  \n",
       "8   0.04  0.95  0.01  \n",
       "9   0.00  1.00  0.00  \n",
       "10  0.01  0.31  0.68  \n",
       "11  0.95  0.05  0.00  \n",
       "12  0.36  0.61  0.04  \n",
       "13  0.00  0.99  0.01  \n",
       "14  0.28  0.71  0.01  \n",
       "15  0.99  0.01  0.00  \n",
       "16  1.00  0.00  0.00  \n",
       "17  0.11  0.88  0.01  \n",
       "18  0.23  0.76  0.01  \n",
       "19  0.00  1.00  0.00  "
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_prob = X_test.copy()\n",
    "X_test_prob.reset_index(drop=True, inplace=True)\n",
    "probs = pd.DataFrame(svc_2.predict_proba(X_test), columns=[0,1,2]).round(2)\n",
    "X_test_prob.merge(probs, left_index=True, right_index=True)[:20]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
